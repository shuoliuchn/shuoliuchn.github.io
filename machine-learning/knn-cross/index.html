<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="Tu5vqPaUb8svfkPx5eetJFD84ciQCcWVXNatdsWtj9Q">
  <meta name="baidu-site-verification" content="baidu_verify_FBq9PG4BBb">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sliu.vip","root":"/","scheme":"Mist","version":"7.7.2","exturl":false,"sidebar":{"position":"right","width":240,"display":"hide","padding":12,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"appID":"PXY1Z6GHKT","apiKey":"eb82f2e78e3053f26aa408e9caa96d93","indexName":"blog","hits":{"per_page":10},"labels":{"input_placeholder":"要查点什么(✿◡‿◡)","hits_empty":"没有找到任何关于 ${query} 的结果╥﹏╥...","hits_stats":"搜索到 ${hits} 条记录，用时 ${time} ms o(*￣▽￣*)ブ"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="简单地说，K-近邻算法（k-Nearest Neighbor，KNN）采用测量不同特征值之间的距离方法进行分类。k 值的选取不同将会影响到我们对测试数据类别的划分，所以不能随意选取。">
<meta property="og:type" content="article">
<meta property="og:title" content="K-近邻算法和交叉验证">
<meta property="og:url" content="https://sliu.vip/machine-learning/knn-cross/index.html">
<meta property="og:site_name" content="刘硕的技术查阅手册">
<meta property="og:description" content="简单地说，K-近邻算法（k-Nearest Neighbor，KNN）采用测量不同特征值之间的距离方法进行分类。k 值的选取不同将会影响到我们对测试数据类别的划分，所以不能随意选取。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://sliu.vip/machine-learning/knn-cross/knnalgorithm.png">
<meta property="article:published_time" content="2020-04-19T16:45:40.138Z">
<meta property="article:modified_time" content="2020-04-19T16:56:16.935Z">
<meta property="article:author" content="刘硕">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Anaconda">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="Scikit-Learn">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://sliu.vip/machine-learning/knn-cross/knnalgorithm.png">

<link rel="canonical" href="https://sliu.vip/machine-learning/knn-cross/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>K-近邻算法和交叉验证 | 刘硕的技术查阅手册</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f14f123935d6183fdd06f8f1c4bc378f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="刘硕的技术查阅手册" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">刘硕的技术查阅手册</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">Python 全栈开发学习笔记</h1>
      
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-toc">

    <a href="/toc/" rel="section"><i class="fa fa-fw fa-book"></i>总目录</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-fw fa-heartbeat"></i>公益 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

  
</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://sliu.vip/machine-learning/knn-cross/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="刘硕">
      <meta itemprop="description" content="不成为自己讨厌的人">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="刘硕的技术查阅手册">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          K-近邻算法和交叉验证
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-04-20 00:45:40 / 修改时间：00:56:16" itemprop="dateCreated datePublished" datetime="2020-04-20T00:45:40+08:00">2020-04-20</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/machine-learning/knn-cross/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/machine-learning/knn-cross/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>12k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>22 分钟</span>
            </span>
            <div class="post-description">简单地说，K-近邻算法（k-Nearest Neighbor，KNN）采用测量不同特征值之间的距离方法进行分类。k 值的选取不同将会影响到我们对测试数据类别的划分，所以不能随意选取。</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="KNN-分类模型"><a href="#KNN-分类模型" class="headerlink" title="KNN 分类模型"></a>KNN 分类模型</h2><p>简单地说，K-近邻算法（k-Nearest Neighbor，KNN）采用测量不同特征值之间的距离方法进行分类。</p>
<img src="/machine-learning/knn-cross/knnalgorithm.png" class="" title="knnalgorithm">

<p>从下面图中对绿色圆点的分类，我们可以了解 k 值对分类的影响。</p>
<p>如果我们将 k 值设置为 3，也就是找到测试数据最接近的 3 个样本数据。根据样本数据的类别数目，来确定测试数据的类别。我们可以计算出测试数据到所有样本数据的距离，然后进行排序，选择最小的三个数据即可。</p>
<p>下图实线圆圈圈起来的就是我们 k 值设置为 3 的情况下，符合条件的最近的 3 个样本数据。我们发现，这三个样本数据中，红色三角有两个，而蓝色方块只有一个。于是我们断定，绿色圆圈属于红色三角类。</p>
<p>但是如果我们将范围扩大，k 值设置为 5。这时就要以虚线圆圈为基准了。五个最近的样本数据中，蓝色方块有三个，红色三角只有两个。所以此时，绿色圆圈应该划归蓝色方块类。</p>


<p>从上面的例子中我们可以看到，k 值的选取不同将会影响到我们对测试数据类别的划分，所以不能随意选取。</p>
<p>我们通过欧几里得距离来计算两点之间的远近：</p>


<h2 id="电影分类"><a href="#电影分类" class="headerlink" title="电影分类"></a>电影分类</h2><p>众所周知，电影可以按照题材分类，然而题材本身是如何定义的？由谁来判定某部电影属于哪个题材？也就是说同一题材的电影具有哪些公共特征？这些都是在进行电影分类时必须要考虑的问题。</p>
<p>没有哪个电影人会说自己制作的电影和以前的某部电影类似，但我们确实知道每部电影在风格 上的确有可能会和同题材的电影相近。那么动作片具有哪些共有特征，使得动作片之间非常类似， 而与爱情片存在着明显的差别呢？</p>
<p>动作片中也会存在接吻镜头，爱情片中也会存在打斗场景，我们不能单纯依靠是否存在打斗或者亲吻来判断影片的类型。但是爱情片中的亲吻镜头更多，动作片中的打斗场景也更频繁，基于此类场景在某部电影中出现的次数可以用来进行电影分类。</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据 与所属分类的对应关系。输人没有标签的新数据后，将新数据的每个特征与样本集中数据对应的 特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。</p>
<p>一般来说，我们只选择样本数据集中前 K 个最相似的数据，这就是 K-近邻算法中K的出处，通常 K 是不大于 20 的整数。 最后 ，选择 K 个最相似数据中出现次数最多的分类，作为新数据的分类。</p>
<p>回到前面电影分类的例子，使用K-近邻算法分类爱情片和动作片。有人曾经统计过很多电影的打斗镜头和接吻镜头，下图显示了 6 部电影的打斗和接吻次数。假如有一部未看过的电影，如何确定它是爱情片还是动作片呢？我们可以使用 K-近邻算法来解决这个问题。</p>


<p>首先我们需要知道这个未知电影存在多少个打斗镜头和接吻镜头，上图中问号位置是该未知电影出现的镜头数图形化展示，具体数字参见下表。</p>


<p>即使不知道未知电影属于哪种类型，我们也可以通过某种方法计算出来。首先计算未知电影与样本集中其他电影的距离，如图所示。</p>


<p>现在我们得到了样本集中所有电影与未知电影的距离，按照距离递增排序，可以找到 K 个距离最近的电影。假定 k=3，则三个最靠近的电影依次是 California Man、He’s Not Really into Dudes、Beautiful Woman。K-近邻算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全是爱情片，因此我们判定未知电影是爱情片。</p>
<h3 id="在-scikit-learn-库中使用-k-近邻算法"><a href="#在-scikit-learn-库中使用-k-近邻算法" class="headerlink" title="在 scikit-learn 库中使用 k-近邻算法"></a>在 scikit-learn 库中使用 k-近邻算法</h3><p>KNN 分类算法 API：<code>from sklearn.neighbors import KNeighborsClassifier</code></p>
<p>首先，从文件中加载电影数据，然后提取特征数据和目标数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_excel(<span class="string">'datasets/my_films.xlsx'</span>)</span><br><span class="line"><span class="comment"># 提取特征数据和目标数据</span></span><br><span class="line">feature = data[[<span class="string">'Action Lens'</span>, <span class="string">'Love Lens'</span>]]    <span class="comment"># 特征数据</span></span><br><span class="line">target = data[<span class="string">'target'</span>]    <span class="comment"># 目标数据</span></span><br></pre></td></tr></table></figure>

<p>然后，将数据拆分成训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(feature, target, random_state=<span class="number">2020</span>, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<p>其中，x_train 和 y_train 为训练集，x_test 和 y_test 为测试集。</p>
<p>接下来，使用训练集训练模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="comment"># n_neighbors就是knn中的k</span></span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">4</span>)    <span class="comment"># 实例化了一个模型对象</span></span><br><span class="line"><span class="comment"># 使用样本数据训练模型（使用训练集训练模型）</span></span><br><span class="line">knn.fit(x_train, y_train)    <span class="comment"># 训练模型，参数X:特征（形状必须是二维），y:目标</span></span><br></pre></td></tr></table></figure>

<p>使用测试集测试模型：</p>
<ul>
<li>测试集中是存在电影真实的分类结果（y_test）</li>
<li>我们需要将测试集的特征数据带入模型，让模型对测试集的电影进行分类，然后使用模型分类的结果和测试集电影真实的结果比对。比对的结果就是模型验证的结果。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_pred = knn.predict(x_test)</span><br><span class="line">print(<span class="string">'模型分类结果：'</span>,y_pred)</span><br><span class="line">print(<span class="string">'真实的分类结果：'</span>,y_test)</span><br></pre></td></tr></table></figure>

<p>输出的结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">模型分类结果： [<span class="string">'Action'</span> <span class="string">'Action'</span> <span class="string">'Love'</span>]</span><br><span class="line">真实的分类结果： <span class="number">2</span>     Action</span><br><span class="line"><span class="number">1</span>     Action</span><br><span class="line"><span class="number">11</span>      Love</span><br><span class="line">Name: target, dtype: object</span><br></pre></td></tr></table></figure>

<p>我们看到，输出结果和预期的测试结果吻合度很高。</p>
<p>但是这里有一个问题：如果我们测试数据很多的话，如果还这么通过观察到方式来判断模型训练的结果，就很不显示。</p>
<p>这时，我们就可以使用 score 方法，来计算预测正确的测试结果所占的必重：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通常可以使用score来对模型进行评分</span></span><br><span class="line">knn.score(x_test, y_test)    <span class="comment"># 参数X，y只的是测试集中的特征和目标数据</span></span><br></pre></td></tr></table></figure>

<p>k 值的不同会导致分类结果的不同，所以模型类的参数 n_neighbors 会直接影响模型的精准度。该参数被称为模型的超参数。</p>
<h3 id="鸢尾花分类的实现"><a href="#鸢尾花分类的实现" class="headerlink" title="鸢尾花分类的实现"></a>鸢尾花分类的实现</h3><p>鸢尾花有不同的品种，根据花瓣和花蕊的长度和宽度，可以对其进行分类。</p>
<p>首先，读取数据，并提取目标数据和特征数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">data = datasets.load_iris()</span><br><span class="line"><span class="comment"># 提取目标和特征</span></span><br><span class="line">feature = data[<span class="string">'data'</span>]</span><br><span class="line">target = data[<span class="string">'target'</span>]</span><br></pre></td></tr></table></figure>

<p>当样本数据提取出来后，需要对数据进行简单观测，查看是否需要进行相关的特征工程操作，可以适当对特征进行预处理。这里是 sklearn 的数据，本身就很好了，暂时不需要进行特征工程相关操作。</p>
<p>然后，拆分训练数据和测试数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train, y_train, x_test, y_test = train_test_split(feature, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<p>接下来，就要创建模型对象，并训练数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line">knn.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>

<p>最后，使用测试数据评估模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn.score(x_test, y_test)</span><br></pre></td></tr></table></figure>

<p>预测准确率为：0.9666666666666667</p>
<p>我们也可以对单个数据进行预测，需要注意的是，要将数据提前转换陈二维矩阵的形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn.predict(x_test[<span class="number">0</span>].reshape((<span class="number">1</span>, <span class="number">-1</span>)))</span><br></pre></td></tr></table></figure>

<p>预测结果为：array([1])</p>
<h3 id="K-的取值问题：学习曲线"><a href="#K-的取值问题：学习曲线" class="headerlink" title="K 的取值问题：学习曲线"></a>K 的取值问题：学习曲线</h3><p>前面的所有例子中，我们都是将 k 也就是 n_neighbors 的参数随意设置一个值。但是我们已经讨论过了，k 的取值会影响到我们的预测结果。选择一个合适的 k 值是很重要的。</p>
<p>我们可以通过使用不同的 K 值训练同一组数据，然后比较预测的结果。结果最好的那个 K 值就是我们采用的。这就是学习曲线的作用</p>
<p>我们还是采用前面鸢尾花分类的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">data = datasets.load_iris()</span><br><span class="line">feature = data[<span class="string">'data'</span>]</span><br><span class="line">target = data[<span class="string">'target'</span>]</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(feature, target, random_state=<span class="number">2020</span>, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<p>这次，我们使用 1-20 之间的所有整数作为 K 值，训练模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">score_list = []</span><br><span class="line">k_list = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">21</span>):</span><br><span class="line">    <span class="comment"># 每次循环使用不同的k值实例化不同的模型对象</span></span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line">    knn.fit(x_train, y_train)</span><br><span class="line">    score_list.append(knn.score(x_test, y_test))</span><br><span class="line">    k_list.append(k)</span><br></pre></td></tr></table></figure>

<p>将获取到的分值数据绘制成图像：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 不同k对应的分值是Series的数据，k对应的是Series的显示索引</span></span><br><span class="line">s = Series(score_list, index=k_list)</span><br><span class="line">plt.plot(s)</span><br><span class="line">plt.xlabel(<span class="string">'k'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'score'</span>)</span><br></pre></td></tr></table></figure>

<p>绘制出来的图像为：</p>


<p>很直观就能看出来，当 k 取 8 的时候，预测的结果是最好的。</p>
<h3 id="交叉验证选取-K-值"><a href="#交叉验证选取-K-值" class="headerlink" title="交叉验证选取 K 值"></a>交叉验证选取 K 值</h3><p>若 K 值较小，则模型复杂度较高，容易发生过拟合，学习的估计误差会增大，预测结果对近邻的实例点非常敏感。</p>
<p>K 值较大可以减少学习的估计误差，但是学习的近似误差会增大，与输入实例较远的训练实例也会对预测起作用，使预测发生错误，k 值增大模型的复杂度会下降。</p>
<p>在应用中，k 值一般取一个比较小的值，通常采用交叉验证法来来选取最优的 K 值。</p>
<p>适用于小数据场景，样本为几千，几万的情况。</p>
<p>拟合度</p>
<ul>
<li>过拟合：在训练数据表现的好，在测试数据表现的不好</li>
<li>欠拟合：在训练数据和测试数据都表现的不好</li>
</ul>
<h3 id="K-折交叉验证"><a href="#K-折交叉验证" class="headerlink" title="K 折交叉验证"></a>K 折交叉验证</h3><p>如果像上面那样直接使用学习曲线来找到 K 值并不是一个很合理的方案。因为我们使用的是固定的测试数据和训练数据。如果测试数据有较多的异常值，或者样本分布不均匀，则有可能会对 K 值的计算造成误差。</p>
<p>我们可以采用 K 这交叉验证的方式来避免这种误差。</p>
<p>目的：</p>
<ul>
<li>更加科学的选出最为适合的模型超参数的取值，然后将超参数的值作用到模型的创建中。</li>
</ul>
<p>思想：</p>
<ul>
<li>将样本的训练数据交叉的拆分出不同的训练集和验证集，使用交叉拆分出不同的训练集和验证集测分别试模型的精准度，然就求出的精准度的均值就是此次交叉验证的结果。将交叉验证作用到不同的超参数中，选取出精准度最高的超参数作为模型创建的超参数即可！</li>
</ul>
<p>实现思路：</p>
<ul>
<li>将数据集平均分割成K个等份</li>
<li>使用 1 份数据作为测试数据，其余作为训练数据</li>
<li>计算测试准确率</li>
<li>使用不同的测试集，重复 2、3 步骤</li>
<li>对准确率做平均，作为对未知数据预测准确率的估计</li>
</ul>


<p>K 折交叉验证的 API</p>
<ul>
<li><code>from sklearn.model_selection import cross_val_score</code></li>
<li><code>cross_val_score(estimator, X, y, cv)</code><ul>
<li>estimator：模型对象</li>
<li>X, y：训练集数据</li>
<li>cv：折数</li>
</ul>
</li>
</ul>
<p>我们还是以鸢尾花的分类数据为例，演示交叉验证在 KNN 中的基本使用。</p>
<p>首先，还是获取数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">data = datasets.load_iris()</span><br><span class="line">feature = data[<span class="string">'data'</span>]</span><br><span class="line">target = data[<span class="string">'target'</span>]</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(feature, target, random_state=<span class="number">2020</span>, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<p>然后，使用训练数据，进行交叉验证。</p>
<p>注意，交叉验证需要使用训练集数据中的训练集训练模型，使用训练集中的验证集来测试模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line">score_arr = cross_val_score(knn, x_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line">score_arr</span><br></pre></td></tr></table></figure>

<p>得到的结果是取用不同训练集的结果组成的数组：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([<span class="number">1.</span>        , <span class="number">1.</span>        , <span class="number">1.</span>        , <span class="number">0.95833333</span>, <span class="number">1.</span>        ])</span><br></pre></td></tr></table></figure>

<p>我们可以对其取均值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">score_arr.mean()    <span class="comment"># 0.9916666666666668</span></span><br></pre></td></tr></table></figure>

<h3 id="交叉验证的学习曲线"><a href="#交叉验证的学习曲线" class="headerlink" title="交叉验证的学习曲线"></a>交叉验证的学习曲线</h3><p>我们在各个的例子中又将 KNN 中的 k 值设置为 5。但这不一定是最佳的选择，所以我们可以来进行选择，找到一个最优的 k。</p>
<p>通过交叉验证结合学习曲线，即可实现这个需求：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">data = datasets.load_iris()</span><br><span class="line">feature = data[<span class="string">'data'</span>]</span><br><span class="line">target = data[<span class="string">'target'</span>]</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(feature, target, random_state=<span class="number">2020</span>, test_size=<span class="number">0.2</span>)</span><br><span class="line">k_list = []</span><br><span class="line">score_list = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">21</span>):</span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line">    <span class="comment"># 交叉验证的结果</span></span><br><span class="line">    score_arr = cross_val_score(knn, x_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line">    score_list.append(score_arr.mean())</span><br><span class="line">    k_list.append(k)</span><br><span class="line">s = Series(score_list, index=k_list)</span><br><span class="line">plt.plot(s)</span><br><span class="line">plt.xlabel(<span class="string">'k'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'score'</span>)</span><br></pre></td></tr></table></figure>

<p>画出的图像为：</p>


<p>从图像来看，当 k 值为 5 或 9 的时候，效果最好。</p>
<h3 id="预测年收入是否大于-50K-美元"><a href="#预测年收入是否大于-50K-美元" class="headerlink" title="预测年收入是否大于 50K 美元"></a>预测年收入是否大于 50K 美元</h3><p>knn 中的目标数据可以为字符串，因为目标数据在 knn 中没有参与运算。</p>
<p>首先，加载数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">'./datasets/adults.txt'</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>

<p>前五行数据为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">	age	workclass	final_weight	education	education_num	marital_status	occupation	relationship	race	sex	capital_gain	capital_loss	hours_per_week	native_country	salary</span><br><span class="line"><span class="number">0</span>	<span class="number">39</span>	State-gov	<span class="number">77516</span>	Bachelors	<span class="number">13</span>	Never-married	Adm-clerical	Not-<span class="keyword">in</span>-family	White	Male	<span class="number">2174</span>	<span class="number">0</span>	<span class="number">40</span>	United-States	&lt;=<span class="number">50</span>K</span><br><span class="line"><span class="number">1</span>	<span class="number">50</span>	Self-emp-<span class="keyword">not</span>-inc	<span class="number">83311</span>	Bachelors	<span class="number">13</span>	Married-civ-spouse	Exec-managerial	Husband	White	Male	<span class="number">0</span>	<span class="number">0</span>	<span class="number">13</span>	United-States	&lt;=<span class="number">50</span>K</span><br><span class="line"><span class="number">2</span>	<span class="number">38</span>	Private	<span class="number">215646</span>	HS-grad	<span class="number">9</span>	Divorced	Handlers-cleaners	Not-<span class="keyword">in</span>-family	White	Male	<span class="number">0</span>	<span class="number">0</span>	<span class="number">40</span>	United-States	&lt;=<span class="number">50</span>K</span><br><span class="line"><span class="number">3</span>	<span class="number">53</span>	Private	<span class="number">234721</span>	<span class="number">11</span>th	<span class="number">7</span>	Married-civ-spouse	Handlers-cleaners	Husband	Black	Male	<span class="number">0</span>	<span class="number">0</span>	<span class="number">40</span>	United-States	&lt;=<span class="number">50</span>K</span><br><span class="line"><span class="number">4</span>	<span class="number">28</span>	Private	<span class="number">338409</span>	Bachelors	<span class="number">13</span>	Married-civ-spouse	Prof-specialty	Wife	Black	Female	<span class="number">0</span>	<span class="number">0</span>	<span class="number">40</span>	Cuba	&lt;=<span class="number">50</span>K</span><br></pre></td></tr></table></figure>

<p>我们看到，这个数据中的特征值太多，而且很多都是非数值型数据，且对结果影响不大。我们可以认为提取其中几个比较重要的数据，针对它们进行运算。这里选择的是 age，occupation，education_num，hours_per_week 这几个特征。而目标值毫无悬念，就是 salary 列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">feature = data[[<span class="string">'age'</span>, <span class="string">'occupation'</span>, <span class="string">'education_num'</span>, <span class="string">'hours_per_week'</span>]]</span><br><span class="line">target = data[<span class="string">'salary'</span>]</span><br><span class="line">feature.head()</span><br></pre></td></tr></table></figure>

<p>这样数据就简洁很多：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">	age	occupation	education_num	hours_per_week</span><br><span class="line"><span class="number">0</span>	<span class="number">39</span>	Adm-clerical	<span class="number">13</span>	<span class="number">40</span></span><br><span class="line"><span class="number">1</span>	<span class="number">50</span>	Exec-managerial	<span class="number">13</span>	<span class="number">13</span></span><br><span class="line"><span class="number">2</span>	<span class="number">38</span>	Handlers-cleaners	<span class="number">9</span>	<span class="number">40</span></span><br><span class="line"><span class="number">3</span>	<span class="number">53</span>	Handlers-cleaners	<span class="number">7</span>	<span class="number">40</span></span><br><span class="line"><span class="number">4</span>	<span class="number">28</span>	Prof-specialty	<span class="number">13</span>	<span class="number">40</span></span><br></pre></td></tr></table></figure>

<p>但是还有一列，也就是工作职位 occupation，里面的数据都是非数值型的。我们需要对其进行特征工程，抽取特征值，也就是进行 One-Hot 编码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将occupation进行one-hot编码：特征值化</span></span><br><span class="line">occ_one_hot = pd.get_dummies(feature[<span class="string">'occupation'</span>])</span><br><span class="line">occ_one_hot.head()</span><br></pre></td></tr></table></figure>

<p>拿到了 occupation 的 One-Hot 编码数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">	?	Adm-clerical	Armed-Forces	Craft-repair	Exec-managerial	Farming-fishing	Handlers-cleaners	Machine-op-inspct	Other-service	Priv-house-serv	Prof-specialty	Protective-serv	Sales	Tech-support	Transport-moving</span><br><span class="line"><span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br><span class="line"><span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br><span class="line"><span class="number">2</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br><span class="line"><span class="number">3</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br><span class="line"><span class="number">4</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>接下来，就是把编码后的 occupation 数据合并到原来的数据中，并删除掉原数据中的 occupation 列：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 经过了特征值化后返回的feature</span></span><br><span class="line">feature = pd.concat((feature, occ_one_hot), axis=<span class="number">1</span>).drop(<span class="string">'occupation'</span>, axis=<span class="number">1</span>)</span><br><span class="line">feature.head()</span><br></pre></td></tr></table></figure>

<p>编码后的 occupation 数据就添加到了原数据中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">	age	education_num	hours_per_week	?	Adm-clerical	Armed-Forces	Craft-repair	Exec-managerial	Farming-fishing	Handlers-cleaners	Machine-op-inspct	Other-service	Priv-house-serv	Prof-specialty	Protective-serv	Sales	Tech-support	Transport-moving</span><br><span class="line"><span class="number">0</span>	<span class="number">39</span>	<span class="number">13</span>	<span class="number">40</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br><span class="line"><span class="number">1</span>	<span class="number">50</span>	<span class="number">13</span>	<span class="number">13</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br><span class="line"><span class="number">2</span>	<span class="number">38</span>	<span class="number">9</span>	<span class="number">40</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br><span class="line"><span class="number">3</span>	<span class="number">53</span>	<span class="number">7</span>	<span class="number">40</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br><span class="line"><span class="number">4</span>	<span class="number">28</span>	<span class="number">13</span>	<span class="number">40</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">1</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span>	<span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>然后，将数据拆分成训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拆分数据:训练数据，测试数据</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(feature, target, random_state=<span class="number">2020</span>, test_size=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure>

<p>接下来，基于交叉验证 + 学习曲线选取最优的 k 值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">k_list = []</span><br><span class="line">score_list = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">50</span>):</span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line">    score_arr = cross_val_score(knn, x_train, y_train, cv=<span class="number">10</span>)</span><br><span class="line">    score_list.append(score_arr.mean())</span><br><span class="line">    k_list.append(k)</span><br></pre></td></tr></table></figure>

<p>绘制学习曲线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series</span><br><span class="line">s = Series(score_list, index=k_list)</span><br><span class="line">plt.plot(s)</span><br><span class="line">plt.xlabel(<span class="string">'k'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'score'</span>)</span><br></pre></td></tr></table></figure>

<p>得到学习曲线：</p>


<p>我们看到当 k 值选取到 20 的时候，就已经足够。</p>
<p>这时，我们就可以使用最优的 k 训练模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">20</span>)</span><br><span class="line">knn.fit(x_train, y_train)</span><br></pre></td></tr></table></figure>

<p>最终使用测试集验证模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn.score(x_test, y_test)</span><br></pre></td></tr></table></figure>

<p>训练得分为：0.7968678028558268</p>
<p>我们可以得到测试集的预测结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn.predict(x_test)</span><br></pre></td></tr></table></figure>

<p>结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array([<span class="string">'&lt;=50K'</span>, <span class="string">'&lt;=50K'</span>, <span class="string">'&lt;=50K'</span>, ..., <span class="string">'&lt;=50K'</span>, <span class="string">'&lt;=50K'</span>, <span class="string">'&lt;=50K'</span>],</span><br><span class="line">      dtype=object)</span><br></pre></td></tr></table></figure>

<h3 id="约会网站配对效果判定"><a href="#约会网站配对效果判定" class="headerlink" title="约会网站配对效果判定"></a>约会网站配对效果判定</h3><p>还是按照原来的流程，首先读取数据出来：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">'datasets/datingTestSet.txt'</span>, sep=<span class="string">'\t'</span>, header=<span class="literal">None</span>)</span><br><span class="line">data</span><br></pre></td></tr></table></figure>

<p>读取来的数据如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">	<span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span>	<span class="number">3</span></span><br><span class="line"><span class="number">0</span>	<span class="number">40920</span>	<span class="number">8.326976</span>	<span class="number">0.953952</span>	largeDoses</span><br><span class="line"><span class="number">1</span>	<span class="number">14488</span>	<span class="number">7.153469</span>	<span class="number">1.673904</span>	smallDoses</span><br><span class="line">...	...	...	...	...</span><br><span class="line"><span class="number">998</span>	<span class="number">48111</span>	<span class="number">9.134528</span>	<span class="number">0.728045</span>	largeDoses</span><br><span class="line"><span class="number">999</span>	<span class="number">43757</span>	<span class="number">7.882601</span>	<span class="number">1.332446</span>	largeDoses</span><br><span class="line"><span class="number">1000</span> rows × <span class="number">4</span> columns</span><br></pre></td></tr></table></figure>

<p>然后提取特征数据和目标数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">feature = data[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]]</span><br><span class="line">target = data[<span class="number">3</span>]</span><br></pre></td></tr></table></figure>

<p>将数据拆分成训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(feature, target, random_state=<span class="number">2020</span>, test_size=<span class="number">0.15</span>)</span><br></pre></td></tr></table></figure>

<p>使用 K 折正交验证确定合适的 K 值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">k_list = []</span><br><span class="line">score_list = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">50</span>):</span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line">    score_arr = cross_val_score(knn, x_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line">    score_list.append(score_arr.mean())</span><br><span class="line">    k_list.append(k)</span><br></pre></td></tr></table></figure>

<p>绘制学习曲线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> Series</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">s = Series(score_list, index=k_list)</span><br><span class="line">plt.plot(s)</span><br><span class="line">plt.xlabel(<span class="string">'k'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'score'</span>)</span><br></pre></td></tr></table></figure>

<p>学习曲线图为：</p>


<p>使用 Series 的 argmax 方法可以直接找到最大值对应的索引：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s.argmax()</span><br></pre></td></tr></table></figure>

<p>当 K 值选取为 20 时，得分最高，效果最好。</p>
<p>最后，将 K 值设置为 20，使用测试集测试训练结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">20</span>)</span><br><span class="line">knn.fit(x_train, y_train)</span><br><span class="line">knn.score(x_test, y_test)</span><br></pre></td></tr></table></figure>

<p>训练的分为：0.8133333333333334</p>
<p>这个得分并不是很高，似乎还有一定的提升空间。</p>
<p>我们看到，三列特征数据数量级差异很大，可以考虑将其进行归一化处理，然后再进行 K 折交叉验证：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">mm = MinMaxScaler()</span><br><span class="line">feature = mm.fit_transform(feature)</span><br><span class="line">target = target</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(feature, target, random_state=<span class="number">2020</span>, test_size=<span class="number">0.15</span>)</span><br><span class="line">score_list = []</span><br><span class="line">k_list = []</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">50</span>):</span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line">    score_arr = cross_val_score(knn, x_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line">    score_list.append(score_arr.mean())</span><br><span class="line">    k_list.append(k)</span><br></pre></td></tr></table></figure>

<p>绘制学习曲线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = Series(score_list, index=k_list)</span><br><span class="line">plt.plot(s)</span><br><span class="line">plt.xlabel(<span class="string">'k'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'score'</span>)</span><br></pre></td></tr></table></figure>

<p>曲线图为：</p>


<p>可以看到当 K 值为 10 附近时，效果最好。找到最大值对应的索引：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s.argmax()</span><br></pre></td></tr></table></figure>

<p>索引值为 13。使用这个索引值，训练数据，并用测试集测试数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">13</span>)</span><br><span class="line">knn.fit(x_train, y_train)</span><br><span class="line">knn.score(x_test, y_test)</span><br></pre></td></tr></table></figure>

<p>新得到的分数为：0.9466666666666667</p>
<p>预测效果好了很多。</p>
<p>如果我们使用标准化对数据进行预处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">feature = data[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]]</span><br><span class="line">feature = ss.fit_transform(feature)</span><br><span class="line">target = target</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(feature, target, random_state=<span class="number">2020</span>, test_size=<span class="number">0.15</span>)</span><br><span class="line">score_list = []</span><br><span class="line">k_list =[]</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">50</span>):</span><br><span class="line">    knn = KNeighborsClassifier(n_neighbors=k)</span><br><span class="line">    score_arr = cross_val_score(knn, x_train, y_train, cv=<span class="number">5</span>)</span><br><span class="line">    score_list.append(score_arr.mean())</span><br><span class="line">    k_list.append(k)</span><br></pre></td></tr></table></figure>

<p>绘制学习曲线：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s = Series(score_list, index=k_list)</span><br><span class="line">plt.plot(s)</span><br><span class="line">plt.xlabel(<span class="string">'k'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'score'</span>)</span><br></pre></td></tr></table></figure>

<p>得到学习曲线为：</p>


<p>结合 argmax 方法，可以得到效果最好的 K 值为：22</p>
<p>使用 22 作为 K 值训练模型，并用测试集测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">knn = KNeighborsClassifier(n_neighbors=<span class="number">22</span>)</span><br><span class="line">knn.fit(x_train, y_train)</span><br><span class="line">knn.score(x_test, y_test)</span><br></pre></td></tr></table></figure>

<p>得到的预测得分为：0.96</p>
<p>效果就更好了。</p>
<h3 id="患癌程度分类预测"><a href="#患癌程度分类预测" class="headerlink" title="患癌程度分类预测"></a>患癌程度分类预测</h3>
    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"># Python</a>
              <a href="/tags/Anaconda/" rel="tag"># Anaconda</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/Scikit-Learn/" rel="tag"># Scikit-Learn</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/machine-learning/naive-bayes/" rel="prev" title="朴素贝叶斯算法">
      <i class="fa fa-chevron-left"></i> 朴素贝叶斯算法
    </a></div>
      <div class="post-nav-item">
    <a href="/machine-learning/sklearn-dataset/" rel="next" title="sklearn 的数据集">
      sklearn 的数据集 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#KNN-分类模型"><span class="nav-number">1.</span> <span class="nav-text">KNN 分类模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#电影分类"><span class="nav-number">2.</span> <span class="nav-text">电影分类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#工作原理"><span class="nav-number">2.1.</span> <span class="nav-text">工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在-scikit-learn-库中使用-k-近邻算法"><span class="nav-number">2.2.</span> <span class="nav-text">在 scikit-learn 库中使用 k-近邻算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#鸢尾花分类的实现"><span class="nav-number">2.3.</span> <span class="nav-text">鸢尾花分类的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-的取值问题：学习曲线"><span class="nav-number">2.4.</span> <span class="nav-text">K 的取值问题：学习曲线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉验证选取-K-值"><span class="nav-number">2.5.</span> <span class="nav-text">交叉验证选取 K 值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-折交叉验证"><span class="nav-number">2.6.</span> <span class="nav-text">K 折交叉验证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉验证的学习曲线"><span class="nav-number">2.7.</span> <span class="nav-text">交叉验证的学习曲线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预测年收入是否大于-50K-美元"><span class="nav-number">2.8.</span> <span class="nav-text">预测年收入是否大于 50K 美元</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#约会网站配对效果判定"><span class="nav-number">2.9.</span> <span class="nav-text">约会网站配对效果判定</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#患癌程度分类预测"><span class="nav-number">2.10.</span> <span class="nav-text">患癌程度分类预测</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="刘硕"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">刘硕</p>
  <div class="site-description" itemprop="description">不成为自己讨厌的人</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">324</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">55</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:liushuo432@outlook.com" title="E-Mail → mailto:liushuo432@outlook.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/2436055290" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;2436055290" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=1696146913&site=qq&menu=yes" title="QQ → http:&#x2F;&#x2F;wpa.qq.com&#x2F;msgrd?v&#x3D;3&amp;uin&#x3D;1696146913&amp;site&#x3D;qq&amp;menu&#x3D;yes" rel="noopener" target="_blank"><i class="fa fa-fw fa-qq"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-fw fa-rss"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="beian"><a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">辽ICP备20001451号 </a>
      <img src="/images/beian_icon.png" style="display: inline-block;"><a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=21142102000063" rel="noopener" target="_blank">辽公网安备 21142102000063号 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘硕</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">1.9m</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">58:29</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.2" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'Ga2II3wuJmHX3GiNHm9TmI97-gzGzoHsz',
      appKey     : 'esGYJQepdYLHf07E1VMsP3RK',
      placeholder: "o(*￣▽￣*)ブ来说点什么吧...（填上邮箱可以收到回复提醒）",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

  <script type="text/javascript" src="/js/love.js"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/Epsilon2.1.model.json"},"display":{"superSample":2,"width":200,"height":400,"position":"left","hOffset":-30,"vOffset":-40},"mobile":{"show":false,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"tagMode":false});</script></body>
</html>
