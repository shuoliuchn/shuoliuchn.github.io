<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>刘硕的技术查阅手册</title>
  
  <subtitle>Python 全栈开发学习笔记</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://sliu.vip/"/>
  <updated>2020-04-04T10:23:53.443Z</updated>
  <id>https://sliu.vip/</id>
  
  <author>
    <name>刘硕</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基于 Pandas 的数据清洗</title>
    <link href="https://sliu.vip/data-analysis/pandas-data-cleaning/"/>
    <id>https://sliu.vip/data-analysis/pandas-data-cleaning/</id>
    <published>2020-04-03T17:43:21.769Z</published>
    <updated>2020-04-04T10:23:53.443Z</updated>
    
    <summary type="html">
    
      我们进行数据分析时，得到的原始数据往往会有一些不合理的地方。比如，因为取样原因可能出现一些空值，重复取样可能会有重复数据，取样错误可能会有异常数据，等等。这些不合理的数据是会影响我们数据分析的准确性的。而明显不合理的数据往往占少数，所以一般我们对其处理的方式是直接删除。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>DataFrame 基础操作巩固 - 股票分析</title>
    <link href="https://sliu.vip/data-analysis/stock-analysis/"/>
    <id>https://sliu.vip/data-analysis/stock-analysis/</id>
    <published>2020-04-02T17:49:49.787Z</published>
    <updated>2020-04-04T10:23:53.439Z</updated>
    
    <summary type="html">
    
      DataFrame 是一个十分强大的数据分析工具，功能很多，一时半会儿学不完。与其枯燥地学习每一个方法，不如结合实际项目应用，一边解决问题，一边学习方法。这样能加深理解，也不至于太乏味。数据分析的一个很重要的应用领域，就是金融量化。我们今天以金融量化中的一种方法，双均值法，来学习 DataFrame 的操作。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>Pandas 的基础操作</title>
    <link href="https://sliu.vip/data-analysis/pandas-basic/"/>
    <id>https://sliu.vip/data-analysis/pandas-basic/</id>
    <published>2020-04-01T17:35:37.205Z</published>
    <updated>2020-04-04T10:23:53.433Z</updated>
    
    <summary type="html">
    
      NumPy 主要用来帮助我们处理的是数值型的数据，当然在数据分析中除了数值型的数据还有好多其他类型的数据（字符串，时间序列）， Pandas 就可以帮我们很好地处理除了数值型的其他数据！
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>NumPy 的基本使用</title>
    <link href="https://sliu.vip/data-analysis/numpy-basic/"/>
    <id>https://sliu.vip/data-analysis/numpy-basic/</id>
    <published>2020-04-01T17:35:37.198Z</published>
    <updated>2020-04-04T10:23:53.428Z</updated>
    
    <summary type="html">
    
      NumPy（Numerical Python）是 Python 语言中做科学计算的基础库。重在于数值计算，也是大部分 Python 科学计算库的基础，多用于在大型、多维数组上执行的数值运算。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="NumPy" scheme="https://sliu.vip/tags/NumPy/"/>
    
  </entry>
  
  <entry>
    <title>数据分析基本概念</title>
    <link href="https://sliu.vip/data-analysis/data-analysis-abc/"/>
    <id>https://sliu.vip/data-analysis/data-analysis-abc/</id>
    <published>2020-04-01T17:35:37.192Z</published>
    <updated>2020-04-04T10:23:53.422Z</updated>
    
    <summary type="html">
    
      我们爬虫可以爬取到大量的数据，公司日常运营，也会产生很多数据。这些数据单独放在那里，并没有什么作用。我们需要对这些数据进行整理归纳和分析，从数据中提取到我们想要的信息，这样才能让这些数据体现出它们应有的价值来。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>狄克斯特拉算法</title>
    <link href="https://sliu.vip/notes/grokking-algorithms-dijkstra/"/>
    <id>https://sliu.vip/notes/grokking-algorithms-dijkstra/</id>
    <published>2020-03-31T16:56:16.182Z</published>
    <updated>2020-04-01T17:35:38.611Z</updated>
    
    <summary type="html">
    
      狄克斯特拉算法用来找到加权图中的最短路径。 广度优先搜索可以找到段数最少的路径，但是如果我们要找到用时最少的路径，就要使用狄克斯特拉算法（Dijkstra&#39;s Algorithm）。
    
    </summary>
    
    
      <category term="学习实践笔记" scheme="https://sliu.vip/categories/%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="算法" scheme="https://sliu.vip/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="算法图解" scheme="https://sliu.vip/tags/%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>selenium 在 scrapy 中的使用</title>
    <link href="https://sliu.vip/crawler/scrapy-selenium/"/>
    <id>https://sliu.vip/crawler/scrapy-selenium/</id>
    <published>2020-03-31T16:56:15.894Z</published>
    <updated>2020-03-31T17:23:50.365Z</updated>
    
    <summary type="html">
    
      一直以来，我们都是直接使用 scrapy 框架的 Request 模块进行网页数据的请求。但是如果网页中有动态加载的数据，这种方式就不容易实现了。其实 scrapy 更多的处理的还是没有动态加载数据的页面。对于动态加载的页面，我们还是比较倾向于使用 requests。但是如果真的有这么个需求，需要我们使用 scrapy 爬取动态页面的话，通过 selenium 发送请求获取数据，将会是一个不错的选择。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
      <category term="selenium" scheme="https://sliu.vip/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>增量式</title>
    <link href="https://sliu.vip/crawler/incremental/"/>
    <id>https://sliu.vip/crawler/incremental/</id>
    <published>2020-03-31T16:56:15.883Z</published>
    <updated>2020-03-31T17:23:50.350Z</updated>
    
    <summary type="html">
    
      对于我们前面的那些爬虫方法，如果我们之前爬取过某个网站，下次再启动工程，还是会从头爬取。即便我们之前爬取过这个网站的很多数据，但是我们还是会对这些爬取过的数据重复爬取。为了减少这种重复爬取的操作，让程序更加集中运行在我们没有爬取过的，新出现的网页中，从而提高爬取效率。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>分布式</title>
    <link href="https://sliu.vip/crawler/distributed/"/>
    <id>https://sliu.vip/crawler/distributed/</id>
    <published>2020-03-31T16:56:15.861Z</published>
    <updated>2020-03-31T17:23:50.345Z</updated>
    
    <summary type="html">
    
      分布式爬虫，是一种能够将爬虫效率发挥到极致的爬虫方法。实现方式：scrapy + redis（完整说法是 scrapy 结合着 scrapy-redis 组件）。scrapy-redis 组件的作用是，可以给原生的 scrapy 框架提供共享的管道和调度器。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>scrapy 高级用法</title>
    <link href="https://sliu.vip/crawler/scrapy-advanced/"/>
    <id>https://sliu.vip/crawler/scrapy-advanced/</id>
    <published>2020-03-31T16:56:15.829Z</published>
    <updated>2020-03-31T17:23:50.331Z</updated>
    
    <summary type="html">
    
      scrapy 的高级用法，包括：scrapy 的五大核心组件的概念和 scrappy 的运行机制；请求传参实现深度爬取，也就是获取详情页的数据；scrapy 的中间件，跟 Django 的中间件很相似；大文件（图片视频等）下载，这是爬虫很重要的应用；settings.py 中的常用配置，一些比较重要的配置方法。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>CrawlSpider 的基本使用</title>
    <link href="https://sliu.vip/crawler/crawlspider/"/>
    <id>https://sliu.vip/crawler/crawlspider/</id>
    <published>2020-03-31T16:56:15.824Z</published>
    <updated>2020-03-31T17:23:50.327Z</updated>
    
    <summary type="html">
    
      CrawlSpider 是 Spider 的一个子类。Spider 是爬虫文件中爬虫类的父类。一般来讲，子类的功能要比父类多，所以 CrawlSpider 的功能是比 Spider 更完善更强大的。CrawlSpider 的作用：常被用作于专业实现全站数据爬取，也就是将一个页面下所有页码对应的数据进行爬取。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>selenium 模块的安装和配置</title>
    <link href="https://sliu.vip/testing/selenium-install/"/>
    <id>https://sliu.vip/testing/selenium-install/</id>
    <published>2020-03-29T16:05:29.891Z</published>
    <updated>2020-03-31T17:23:50.322Z</updated>
    
    <summary type="html">
    
      包括 selenium IDE 的安装何使用、selenium 的安装和浏览器驱动的下载配置。只有配置好，才能正常使用 selenium 爬取数据。
    
    </summary>
    
    
      <category term="测试" scheme="https://sliu.vip/categories/%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="selenium" scheme="https://sliu.vip/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>selenium 的基本操作</title>
    <link href="https://sliu.vip/testing/selenium-basic/"/>
    <id>https://sliu.vip/testing/selenium-basic/</id>
    <published>2020-03-29T16:05:29.886Z</published>
    <updated>2020-03-31T17:23:50.307Z</updated>
    
    <summary type="html">
    
      selenium 是一款基于浏览器的自动化爬虫工具，可以给我们的测试开发提供极大的便利。这里介绍了一些 selenium 常用的使用方法。
    
    </summary>
    
    
      <category term="测试" scheme="https://sliu.vip/categories/%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="selenium" scheme="https://sliu.vip/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>Django 操作阿里云表格存储 Tablestore</title>
    <link href="https://sliu.vip/project/renran-tablestore/"/>
    <id>https://sliu.vip/project/renran-tablestore/</id>
    <published>2020-03-29T16:05:29.778Z</published>
    <updated>2020-03-31T17:23:50.303Z</updated>
    
    <summary type="html">
    
      Tablestore 目前只支持四种数据类型：INTEGER、STRING、DOUBLE 和 BOOLEAN。其中 DOUBLE 类型不能做主键类型，BOOLEAN 不可以做主键的第一列（分区键）。
    
    </summary>
    
    
      <category term="综合项目" scheme="https://sliu.vip/categories/%E7%BB%BC%E5%90%88%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="数据库" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="实践项目" scheme="https://sliu.vip/tags/%E5%AE%9E%E8%B7%B5%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="荏苒资讯" scheme="https://sliu.vip/tags/%E8%8D%8F%E8%8B%92%E8%B5%84%E8%AE%AF/"/>
    
  </entry>
  
  <entry>
    <title>Feed 流系统概述</title>
    <link href="https://sliu.vip/project/renran-feed-flow/"/>
    <id>https://sliu.vip/project/renran-feed-flow/</id>
    <published>2020-03-29T16:05:29.772Z</published>
    <updated>2020-03-31T17:23:50.287Z</updated>
    
    <summary type="html">
    
      在信息工程中，Feed 其实是一个信息单元，比如一条朋友圈状态、一条微博、一条咨询或一条短视频等。Feed 流就是不停更新的信息单元，只要关注某些发布者就能获取到源源不断的新鲜信息，我们的用户也就可以在移动设备上逐条去浏览这些信息单元。当前最流行的 Feed 流产品有微博、微信朋友圈、头条的资讯推荐、快手抖音的视频推荐等。还有一些变种，比如私信、通知等，这些系统都是 Feed 流系统。接下来我们将介绍如何设计一个 Feed 流系统架构。
    
    </summary>
    
    
      <category term="综合项目" scheme="https://sliu.vip/categories/%E7%BB%BC%E5%90%88%E9%A1%B9%E7%9B%AE/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="实践项目" scheme="https://sliu.vip/tags/%E5%AE%9E%E8%B7%B5%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="荏苒资讯" scheme="https://sliu.vip/tags/%E8%8D%8F%E8%8B%92%E8%B5%84%E8%AE%AF/"/>
    
  </entry>
  
  <entry>
    <title>Redis 的基本使用</title>
    <link href="https://sliu.vip/database/redis-abc/"/>
    <id>https://sliu.vip/database/redis-abc/</id>
    <published>2020-03-29T16:05:29.674Z</published>
    <updated>2020-03-31T17:23:50.283Z</updated>
    
    <summary type="html">
    
      Redis 是一种内存型（数据存放在内存中）的非关系型（NOSQL）key-value（键值存储）数据库，支持数据的持久化（注：数据持久化时将数据存放到文件中，每次启动 Redis 之后会先将文件中数据加载到内存），经常用做缓存（用来缓存一些经常用到的数据，提高读写速度）。
    
    </summary>
    
    
      <category term="数据库" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Redis" scheme="https://sliu.vip/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis 的安装和配置</title>
    <link href="https://sliu.vip/database/redis-install/"/>
    <id>https://sliu.vip/database/redis-install/</id>
    <published>2020-03-29T16:05:29.668Z</published>
    <updated>2020-03-31T17:23:50.278Z</updated>
    
    <summary type="html">
    
      Redis 是一款高性能，内存数据存储的非关系型数据库。通常用来进行数据缓存，也就是存放一些需要经常读取的数据。这里介绍各个系统下 Redis 的安装和配置方法。
    
    </summary>
    
    
      <category term="数据库" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Redis" scheme="https://sliu.vip/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Python 操作 Redis</title>
    <link href="https://sliu.vip/database/redis-python/"/>
    <id>https://sliu.vip/database/redis-python/</id>
    <published>2020-03-29T16:05:29.659Z</published>
    <updated>2020-03-31T17:23:50.263Z</updated>
    
    <summary type="html">
    
      Python 有很多的模块都可以实现对 Redis 的操作，常用有 redis 和 pyredis，这两个模块的使用操作是类似的。这里我们使用 redis 模块来进行演示。
    
    </summary>
    
    
      <category term="数据库" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="数据库" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Redis" scheme="https://sliu.vip/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>广度优先搜索</title>
    <link href="https://sliu.vip/notes/grokking-algorithms-bfs/"/>
    <id>https://sliu.vip/notes/grokking-algorithms-bfs/</id>
    <published>2020-03-29T16:05:29.625Z</published>
    <updated>2020-03-31T17:23:50.259Z</updated>
    
    <summary type="html">
    
      广度优先搜索让我们能够找出两样东西之间的最短距离。广度优先搜索是一种用于图的查找算法，可帮助回答两类问题：1. 从节点 A 出发，有前往节点 B 的路径吗？2. 从节点 A 出发，前往节点 B 的哪条路径最短？
    
    </summary>
    
    
      <category term="学习实践笔记" scheme="https://sliu.vip/categories/%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="算法" scheme="https://sliu.vip/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="算法图解" scheme="https://sliu.vip/tags/%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>异步爬虫</title>
    <link href="https://sliu.vip/crawler/async-crawler/"/>
    <id>https://sliu.vip/crawler/async-crawler/</id>
    <published>2020-03-29T16:05:29.350Z</published>
    <updated>2020-03-31T17:23:50.243Z</updated>
    
    <summary type="html">
    
      异步爬虫的作用很显而易见，就是为了提高我们爬虫的效率。因为网络请求通常会消耗一点时间，普通的爬虫在网络请求这段时间会诸塞住，CPU 的资源是浪费掉了。使用异步爬虫，就是在一个任务请求数据的时候，把 CPU 让出来，处理其他任务，从而提高爬虫的效率。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="requests" scheme="https://sliu.vip/tags/requests/"/>
    
      <category term="并发编程" scheme="https://sliu.vip/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
</feed>
