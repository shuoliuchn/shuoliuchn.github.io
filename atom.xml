<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>刘硕的技术查阅手册</title>
  
  <subtitle>Python 全栈开发学习笔记</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://sliu.vip/"/>
  <updated>2020-04-08T04:29:27.401Z</updated>
  <id>https://sliu.vip/</id>
  
  <author>
    <name>刘硕</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据分析总结</title>
    <link href="https://sliu.vip/data-analysis/data-analysis-summary/"/>
    <id>https://sliu.vip/data-analysis/data-analysis-summary/</id>
    <published>2020-04-07T17:13:27.363Z</published>
    <updated>2020-04-08T04:29:27.401Z</updated>
    
    <summary type="html">
    
      总结一下数据分析三剑客（NumPy、Pandas 和 Matplotlib）的常用方法。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="NumPy" scheme="https://sliu.vip/tags/NumPy/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
      <category term="Matplotlib" scheme="https://sliu.vip/tags/Matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>用户消费行为分析案例</title>
    <link href="https://sliu.vip/data-analysis/consumption-behavior/"/>
    <id>https://sliu.vip/data-analysis/consumption-behavior/</id>
    <published>2020-04-07T17:13:27.347Z</published>
    <updated>2020-04-08T04:29:27.397Z</updated>
    
    <summary type="html">
    
      电商平台每天都会产生大量的用户购买商品的消费行为数据。通过分析这些数据，我们可以了解电商的运营情况，用户的消费规律等信息。有了这些信息，我们可以完善平台建设，预测用户的消费行为，从而提高用户体验。这个案例将综合使用我们数据分析的各种模块。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="NumPy" scheme="https://sliu.vip/tags/NumPy/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
      <category term="Matplotlib" scheme="https://sliu.vip/tags/Matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>2012 美国大选献金项目数据分析</title>
    <link href="https://sliu.vip/data-analysis/political-contributions/"/>
    <id>https://sliu.vip/data-analysis/political-contributions/</id>
    <published>2020-04-06T17:44:28.573Z</published>
    <updated>2020-04-08T04:29:27.392Z</updated>
    
    <summary type="html">
    
      众所周知，美国大选是一个非常耗钱的事情。每个总统参加竞选时，都需要大量的经费。这些经费，几乎不会由候选人自己出，它们往往来自于政治献金。通过对政治献金数据的分析，练习一下 Pandas 的各种方法。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>Matplotlib 绘图基础</title>
    <link href="https://sliu.vip/data-analysis/matplotlib-basic/"/>
    <id>https://sliu.vip/data-analysis/matplotlib-basic/</id>
    <published>2020-04-06T17:44:28.526Z</published>
    <updated>2020-04-08T04:29:27.389Z</updated>
    
    <summary type="html">
    
      我们使用 Pandas 千辛万苦处理出来一些数据，却发现，这些数据仍然很抽象。如果没有参与运算，或者对数字不是那么敏感的话，可能一时找不到这里面的规律。这时，我们可以考虑把数据绘制成图表，让其仍容易理解，一目了然。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Matplotlib" scheme="https://sliu.vip/tags/Matplotlib/"/>
    
  </entry>
  
  <entry>
    <title>seaborn 基本用法</title>
    <link href="https://sliu.vip/data-analysis/seaborn-abc/"/>
    <id>https://sliu.vip/data-analysis/seaborn-abc/</id>
    <published>2020-04-06T17:44:28.521Z</published>
    <updated>2020-04-08T04:29:27.385Z</updated>
    
    <summary type="html">
    
      除了 Matplotlib 之外，seaborn 也是一个用来绘制图像，实现数据可视化的工具。Matplotlib 试着让简单的事情更加简单，困难的事情变得可能，而 seaborn 就是让困难的东西更加简单。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="seaborn" scheme="https://sliu.vip/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>DataFrame 的级联与合并操作</title>
    <link href="https://sliu.vip/data-analysis/df-concate-merge/"/>
    <id>https://sliu.vip/data-analysis/df-concate-merge/</id>
    <published>2020-04-05T16:39:58.232Z</published>
    <updated>2020-04-08T04:29:27.382Z</updated>
    
    <summary type="html">
    
      有的时候，我们的数据可能会来自不同的文件。读取每个文件时，会产生一个 DataFrame。如果我们想要综合这些文件中的数据，就需要将多个表格整合成一个大表格。就类似于我们使用 MySQL 数据库，对于不同表进行的联表操作一样。要将多个 DataFrame 整合成一个大的综合的 DataFrame，就需要使用到 DataFrame 的级联与合并操作。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>Pandas 高级操作</title>
    <link href="https://sliu.vip/data-analysis/pandas-advanced/"/>
    <id>https://sliu.vip/data-analysis/pandas-advanced/</id>
    <published>2020-04-05T16:39:58.210Z</published>
    <updated>2020-04-08T04:29:27.378Z</updated>
    
    <summary type="html">
    
      Pandas 的一些高级用法，包括：替换操作、映射操作、运算工具、排序实现的随机抽样、数据的分类分组处理、高级数据聚合、数据加载、透视表和交叉表等操作。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>人口分析案例</title>
    <link href="https://sliu.vip/data-analysis/population-analysis/"/>
    <id>https://sliu.vip/data-analysis/population-analysis/</id>
    <published>2020-04-05T16:39:58.197Z</published>
    <updated>2020-04-08T04:29:27.375Z</updated>
    
    <summary type="html">
    
      现有美国各州数年人口普查的数据，需要进行各种分析操作。主要用来练习一些 Pandas 的常用方法。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>基于 Pandas 的数据清洗</title>
    <link href="https://sliu.vip/data-analysis/pandas-data-cleaning/"/>
    <id>https://sliu.vip/data-analysis/pandas-data-cleaning/</id>
    <published>2020-04-03T17:43:21.769Z</published>
    <updated>2020-04-05T16:39:59.547Z</updated>
    
    <summary type="html">
    
      我们进行数据分析时，得到的原始数据往往会有一些不合理的地方。比如，因为取样原因可能出现一些空值，重复取样可能会有重复数据，取样错误可能会有异常数据，等等。这些不合理的数据是会影响我们数据分析的准确性的。而明显不合理的数据往往占少数，所以一般我们对其处理的方式是直接删除。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>DataFrame 基础操作巩固 - 股票分析</title>
    <link href="https://sliu.vip/data-analysis/stock-analysis/"/>
    <id>https://sliu.vip/data-analysis/stock-analysis/</id>
    <published>2020-04-02T17:49:49.787Z</published>
    <updated>2020-04-04T10:23:53.439Z</updated>
    
    <summary type="html">
    
      DataFrame 是一个十分强大的数据分析工具，功能很多，一时半会儿学不完。与其枯燥地学习每一个方法，不如结合实际项目应用，一边解决问题，一边学习方法。这样能加深理解，也不至于太乏味。数据分析的一个很重要的应用领域，就是金融量化。我们今天以金融量化中的一种方法，双均值法，来学习 DataFrame 的操作。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>Pandas 的基础操作</title>
    <link href="https://sliu.vip/data-analysis/pandas-basic/"/>
    <id>https://sliu.vip/data-analysis/pandas-basic/</id>
    <published>2020-04-01T17:35:37.205Z</published>
    <updated>2020-04-04T10:23:53.433Z</updated>
    
    <summary type="html">
    
      NumPy 主要用来帮助我们处理的是数值型的数据，当然在数据分析中除了数值型的数据还有好多其他类型的数据（字符串，时间序列）， Pandas 就可以帮我们很好地处理除了数值型的其他数据！
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="Pandas" scheme="https://sliu.vip/tags/Pandas/"/>
    
  </entry>
  
  <entry>
    <title>NumPy 的基本使用</title>
    <link href="https://sliu.vip/data-analysis/numpy-basic/"/>
    <id>https://sliu.vip/data-analysis/numpy-basic/</id>
    <published>2020-04-01T17:35:37.198Z</published>
    <updated>2020-04-04T10:23:53.428Z</updated>
    
    <summary type="html">
    
      NumPy（Numerical Python）是 Python 语言中做科学计算的基础库。重在于数值计算，也是大部分 Python 科学计算库的基础，多用于在大型、多维数组上执行的数值运算。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="NumPy" scheme="https://sliu.vip/tags/NumPy/"/>
    
  </entry>
  
  <entry>
    <title>数据分析基本概念</title>
    <link href="https://sliu.vip/data-analysis/data-analysis-abc/"/>
    <id>https://sliu.vip/data-analysis/data-analysis-abc/</id>
    <published>2020-04-01T17:35:37.192Z</published>
    <updated>2020-04-04T10:23:53.422Z</updated>
    
    <summary type="html">
    
      我们爬虫可以爬取到大量的数据，公司日常运营，也会产生很多数据。这些数据单独放在那里，并没有什么作用。我们需要对这些数据进行整理归纳和分析，从数据中提取到我们想要的信息，这样才能让这些数据体现出它们应有的价值来。
    
    </summary>
    
    
      <category term="数据分析" scheme="https://sliu.vip/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="Anaconda" scheme="https://sliu.vip/tags/Anaconda/"/>
    
      <category term="数据分析" scheme="https://sliu.vip/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>狄克斯特拉算法</title>
    <link href="https://sliu.vip/notes/grokking-algorithms-dijkstra/"/>
    <id>https://sliu.vip/notes/grokking-algorithms-dijkstra/</id>
    <published>2020-03-31T16:56:16.182Z</published>
    <updated>2020-04-07T17:13:28.820Z</updated>
    
    <summary type="html">
    
      狄克斯特拉算法用来找到加权图中的最短路径。 广度优先搜索可以找到段数最少的路径，但是如果我们要找到用时最少的路径，就要使用狄克斯特拉算法（Dijkstra&#39;s Algorithm）。
    
    </summary>
    
    
      <category term="学习实践笔记" scheme="https://sliu.vip/categories/%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="算法" scheme="https://sliu.vip/tags/%E7%AE%97%E6%B3%95/"/>
    
      <category term="算法图解" scheme="https://sliu.vip/tags/%E7%AE%97%E6%B3%95%E5%9B%BE%E8%A7%A3/"/>
    
  </entry>
  
  <entry>
    <title>selenium 在 scrapy 中的使用</title>
    <link href="https://sliu.vip/crawler/scrapy-selenium/"/>
    <id>https://sliu.vip/crawler/scrapy-selenium/</id>
    <published>2020-03-31T16:56:15.894Z</published>
    <updated>2020-03-31T17:23:50.365Z</updated>
    
    <summary type="html">
    
      一直以来，我们都是直接使用 scrapy 框架的 Request 模块进行网页数据的请求。但是如果网页中有动态加载的数据，这种方式就不容易实现了。其实 scrapy 更多的处理的还是没有动态加载数据的页面。对于动态加载的页面，我们还是比较倾向于使用 requests。但是如果真的有这么个需求，需要我们使用 scrapy 爬取动态页面的话，通过 selenium 发送请求获取数据，将会是一个不错的选择。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
      <category term="selenium" scheme="https://sliu.vip/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>增量式</title>
    <link href="https://sliu.vip/crawler/incremental/"/>
    <id>https://sliu.vip/crawler/incremental/</id>
    <published>2020-03-31T16:56:15.883Z</published>
    <updated>2020-03-31T17:23:50.350Z</updated>
    
    <summary type="html">
    
      对于我们前面的那些爬虫方法，如果我们之前爬取过某个网站，下次再启动工程，还是会从头爬取。即便我们之前爬取过这个网站的很多数据，但是我们还是会对这些爬取过的数据重复爬取。为了减少这种重复爬取的操作，让程序更加集中运行在我们没有爬取过的，新出现的网页中，从而提高爬取效率。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>分布式</title>
    <link href="https://sliu.vip/crawler/distributed/"/>
    <id>https://sliu.vip/crawler/distributed/</id>
    <published>2020-03-31T16:56:15.861Z</published>
    <updated>2020-03-31T17:23:50.345Z</updated>
    
    <summary type="html">
    
      分布式爬虫，是一种能够将爬虫效率发挥到极致的爬虫方法。实现方式：scrapy + redis（完整说法是 scrapy 结合着 scrapy-redis 组件）。scrapy-redis 组件的作用是，可以给原生的 scrapy 框架提供共享的管道和调度器。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>scrapy 高级用法</title>
    <link href="https://sliu.vip/crawler/scrapy-advanced/"/>
    <id>https://sliu.vip/crawler/scrapy-advanced/</id>
    <published>2020-03-31T16:56:15.829Z</published>
    <updated>2020-03-31T17:23:50.331Z</updated>
    
    <summary type="html">
    
      scrapy 的高级用法，包括：scrapy 的五大核心组件的概念和 scrappy 的运行机制；请求传参实现深度爬取，也就是获取详情页的数据；scrapy 的中间件，跟 Django 的中间件很相似；大文件（图片视频等）下载，这是爬虫很重要的应用；settings.py 中的常用配置，一些比较重要的配置方法。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>CrawlSpider 的基本使用</title>
    <link href="https://sliu.vip/crawler/crawlspider/"/>
    <id>https://sliu.vip/crawler/crawlspider/</id>
    <published>2020-03-31T16:56:15.824Z</published>
    <updated>2020-03-31T17:23:50.327Z</updated>
    
    <summary type="html">
    
      CrawlSpider 是 Spider 的一个子类。Spider 是爬虫文件中爬虫类的父类。一般来讲，子类的功能要比父类多，所以 CrawlSpider 的功能是比 Spider 更完善更强大的。CrawlSpider 的作用：常被用作于专业实现全站数据爬取，也就是将一个页面下所有页码对应的数据进行爬取。
    
    </summary>
    
    
      <category term="爬虫" scheme="https://sliu.vip/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://sliu.vip/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>selenium 模块的安装和配置</title>
    <link href="https://sliu.vip/testing/selenium-install/"/>
    <id>https://sliu.vip/testing/selenium-install/</id>
    <published>2020-03-29T16:05:29.891Z</published>
    <updated>2020-03-31T17:23:50.322Z</updated>
    
    <summary type="html">
    
      包括 selenium IDE 的安装何使用、selenium 的安装和浏览器驱动的下载配置。只有配置好，才能正常使用 selenium 爬取数据。
    
    </summary>
    
    
      <category term="测试" scheme="https://sliu.vip/categories/%E6%B5%8B%E8%AF%95/"/>
    
    
      <category term="Python" scheme="https://sliu.vip/tags/Python/"/>
    
      <category term="爬虫" scheme="https://sliu.vip/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="selenium" scheme="https://sliu.vip/tags/selenium/"/>
    
  </entry>
  
</feed>
